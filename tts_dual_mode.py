import sys
import os
import yaml
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QPushButton, QTextEdit, QLabel,
                             QSlider, QFileDialog, QMessageBox, QTabWidget,
                             QComboBox, QRadioButton, QButtonGroup, QCheckBox)
from PyQt5.QtCore import Qt, QUrl
from PyQt5.QtMultimedia import QMediaPlayer, QMediaContent
import argparse
import torch
import re
from string import punctuation
from langdetect import detect, detect_langs, LangDetectException
import tempfile
from pydub import AudioSegment

from utils.model import get_model, get_vocoder
from utils.tools import to_device, synth_samples, plot_mel
from dataset import TextDataset
from text import text_to_sequence
import text.vietnamese_phonemes as viphonemes

# Import c√°c h√†m t·ª´ synthesize.py
from synthesize import (read_lexicon, preprocess_vietnamese, 
                      preprocess_english, clean_vietnamese_text)

class SpectrogramCanvas(FigureCanvas):
    def __init__(self, parent=None, width=5, height=4, dpi=100):
        self.fig, self.ax = plt.subplots(figsize=(width, height), dpi=dpi)
        super(SpectrogramCanvas, self).__init__(self.fig)
        self.setParent(parent)
        self.fig.tight_layout()
        
    def plot_spectrogram(self, mel, pitch, energy, stats):
        self.ax.clear()
        pitch_min, pitch_max, pitch_mean, pitch_std, energy_min, energy_max = stats
        pitch = pitch * pitch_std + pitch_mean
        
        self.ax.imshow(mel, origin="lower", aspect="auto")
        self.ax.set_title("Spectrogram", fontsize="medium")
        self.ax.tick_params(labelsize="x-small", left=False, labelleft=False)
        
        ax1 = self.ax.twinx()
        ax1.plot(pitch, color="tomato")
        ax1.set_ylim(0, pitch_max)
        ax1.set_ylabel("F0", color="tomato")
        ax1.tick_params(labelsize="x-small", colors="tomato")
        
        ax2 = self.ax.twinx()
        ax2.spines["right"].set_position(("axes", 1.1))
        ax2.plot(energy, color="darkviolet")
        ax2.set_ylim(energy_min, energy_max)
        ax2.set_ylabel("Energy", color="darkviolet")
        ax2.tick_params(labelsize="x-small", colors="darkviolet")
        
        self.fig.tight_layout()
        self.draw()

class DualModeTTSGUI(QMainWindow):
    def __init__(self):
        super().__init__()
        
        # C·∫•u h√¨nh m·∫∑c ƒë·ªãnh
        self.vi_preprocess_config_path = "config/infore/preprocess.yaml"
        self.vi_model_config_path = "config/infore/model.yaml"
        self.vi_train_config_path = "config/infore/train.yaml"
        self.vi_restore_step = 100000
        
        self.en_preprocess_config_path = "config/LJSpeech/preprocess.yaml"
        self.en_model_config_path = "config/LJSpeech/model.yaml"
        self.en_train_config_path = "config/LJSpeech/train.yaml"
        self.en_restore_step = 900000
        
        # C√°c th√¥ng s·ªë ƒëi·ªÅu ch·ªânh
        self.pitch_control = 1.0
        self.energy_control = 1.0
        self.duration_control = 1.0
        
        # ƒê∆∞·ªùng d·∫´n l∆∞u file √¢m thanh
        self.audio_path = None
        
        # Media player
        self.player = QMediaPlayer()
        
        # Ng√¥n ng·ªØ hi·ªán t·∫°i
        self.current_language = "vi"  # M·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát
        
        # Ch·∫ø ƒë·ªô ƒëa ng√¥n ng·ªØ
        self.multi_language_mode = False
        
        # Models
        self.vi_model = None
        self.vi_vocoder = None
        self.vi_preprocess_config = None
        self.vi_model_config = None
        self.vi_train_config = None
        self.vi_stats = None
        
        self.en_model = None
        self.en_vocoder = None
        self.en_preprocess_config = None
        self.en_model_config = None
        self.en_train_config = None
        self.en_stats = None
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        self.init_ui()
        
    def detect_language(self, text):
        """T·ª± ƒë·ªông nh·∫≠n d·∫°ng ng√¥n ng·ªØ c·ªßa vƒÉn b·∫£n"""
        try:
            # Chia vƒÉn b·∫£n th√†nh c√°c c√¢u
            sentences = text.split('.')
            vi_count = 0
            en_count = 0
            
            for sentence in sentences:
                if not sentence.strip():
                    continue
                    
                try:
                    # S·ª≠ d·ª•ng langdetect ƒë·ªÉ nh·∫≠n d·∫°ng ng√¥n ng·ªØ
                    lang = detect(sentence)
                    
                    # ƒê·∫øm s·ªë l∆∞·ª£ng c√¢u theo ng√¥n ng·ªØ
                    if lang == 'vi':
                        vi_count += 1
                    elif lang == 'en':
                        en_count += 1
                except LangDetectException:
                    continue
            
            # So s√°nh s·ªë l∆∞·ª£ng c√¢u ƒë·ªÉ quy·∫øt ƒë·ªãnh ng√¥n ng·ªØ ch√≠nh
            if vi_count >= en_count:
                return "vi"
            else:
                return "en"
                
        except Exception as e:
            print(f"L·ªói nh·∫≠n d·∫°ng ng√¥n ng·ªØ: {e}")
            return "vi"  # M·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát n·∫øu c√≥ l·ªói
            
    def detect_language_for_segment(self, text):
        """Nh·∫≠n d·∫°ng ng√¥n ng·ªØ cho m·ªôt ƒëo·∫°n vƒÉn b·∫£n ng·∫Øn"""
        try:
            lang = detect(text)
            if lang == 'vi':
                return "vi"
            elif lang == 'en':
                return "en"
            return "vi"  # M·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát
        except Exception as e:
            print(f"L·ªói nh·∫≠n d·∫°ng ng√¥n ng·ªØ cho ƒëo·∫°n vƒÉn b·∫£n: {e}")
            return "vi"  # M·∫∑c ƒë·ªãnh l√† ti·∫øng Vi·ªát n·∫øu c√≥ l·ªói
    
    def split_text_by_language(self, text):
        """T√°ch vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n theo ng√¥n ng·ªØ"""
        # T√°ch vƒÉn b·∫£n th√†nh c√°c t·ª´ v√† d·∫•u c√¢u
        segments = []
        current_segment = ""
        current_lang = None
        
        # T√°ch vƒÉn b·∫£n th√†nh c√°c t·ª´ v√† c·ª•m t·ª´
        words = re.findall(r'\w+|[^\w\s]', text)
        
        for word in words:
            if not word.strip():
                continue
                
            # N·∫øu t·ª´ ch·ªâ ch·ª©a d·∫•u c√¢u, th√™m v√†o ƒëo·∫°n hi·ªán t·∫°i
            if not re.search(r'\w', word):
                if current_segment:
                    current_segment += word
                continue
                
            # Th·ª≠ nh·∫≠n d·∫°ng ng√¥n ng·ªØ cho c·ª•m t·ª´ ƒë·ªß d√†i
            if len(word) > 3:
                try:
                    word_lang = self.detect_language_for_segment(word)
                    
                    # N·∫øu ƒëo·∫°n hi·ªán t·∫°i tr·ªëng ho·∫∑c c√πng ng√¥n ng·ªØ, th√™m t·ª´ v√†o
                    if current_lang is None:
                        current_lang = word_lang
                        current_segment = word
                    elif current_lang == word_lang:
                        current_segment += " " + word
                    else:
                        # N·∫øu kh√°c ng√¥n ng·ªØ, l∆∞u ƒëo·∫°n hi·ªán t·∫°i v√† b·∫Øt ƒë·∫ßu ƒëo·∫°n m·ªõi
                        if current_segment:
                            segments.append((current_segment, current_lang))
                        current_segment = word
                        current_lang = word_lang
                except:
                    # N·∫øu kh√¥ng nh·∫≠n d·∫°ng ƒë∆∞·ª£c, th√™m v√†o ƒëo·∫°n hi·ªán t·∫°i
                    if current_segment:
                        current_segment += " " + word
                    else:
                        current_segment = word
                        current_lang = "vi"  # M·∫∑c ƒë·ªãnh
            else:
                # T·ª´ qu√° ng·∫Øn, th√™m v√†o ƒëo·∫°n hi·ªán t·∫°i
                if current_segment:
                    current_segment += " " + word
                else:
                    current_segment = word
                    current_lang = "vi"  # M·∫∑c ƒë·ªãnh
        
        # Th√™m ƒëo·∫°n cu·ªëi c√πng n·∫øu c√≥
        if current_segment:
            segments.append((current_segment, current_lang))
            
        return segments

    def init_ui(self):
        self.setWindowTitle('ƒêa Ng√¥n Ng·ªØ Text-to-Speech üåç')
        self.setGeometry(100, 100, 1000, 800)
        
        main_widget = QWidget()
        main_layout = QVBoxLayout()
        
        # Text input section
        self.text_label = QLabel("Nh·∫≠p vƒÉn b·∫£n:")
        self.text_input = QTextEdit()
        self.text_input.setPlaceholderText("Nh·∫≠p vƒÉn b·∫£n v√†o ƒë√¢y...")
        self.text_input.textChanged.connect(self.on_text_changed)
        
        # Language detection label
        self.language_label = QLabel("Ng√¥n ng·ªØ ph√°t hi·ªán: Ch∆∞a c√≥ vƒÉn b·∫£n")
        self.language_label.setStyleSheet("color: blue;")
        
        # Multilanguage mode checkbox
        self.multi_language_checkbox = QCheckBox("Ch·∫ø ƒë·ªô ƒëa ng√¥n ng·ªØ (x·ª≠ l√Ω t·ª´ng ph·∫ßn vƒÉn b·∫£n theo ng√¥n ng·ªØ ri√™ng) üîÑ")
        self.multi_language_checkbox.toggled.connect(self.toggle_multi_language_mode)
        
        # Buttons
        button_layout = QHBoxLayout()
        self.generate_button = QPushButton("T·∫°o Audio üîä")
        self.generate_button.clicked.connect(self.generate_speech)
        self.play_button = QPushButton("Ph√°t Audio ‚ñ∂Ô∏è")
        self.play_button.clicked.connect(self.play_audio)
        self.save_button = QPushButton("L∆∞u Audio üíæ")
        self.save_button.clicked.connect(self.save_audio)
        self.load_models_button = QPushButton("T·∫£i Models üì•")
        self.load_models_button.clicked.connect(self.load_both_models)
        
        button_layout.addWidget(self.generate_button)
        button_layout.addWidget(self.play_button)
        button_layout.addWidget(self.save_button)
        button_layout.addWidget(self.load_models_button)
        
        # Control sliders
        control_layout = QVBoxLayout()
        
        pitch_layout = QHBoxLayout()
        pitch_label = QLabel("ƒê·ªô cao:")
        self.pitch_slider = QSlider(Qt.Horizontal)
        self.pitch_slider.setRange(50, 150)
        self.pitch_slider.setValue(100)
        self.pitch_slider.valueChanged.connect(self.update_pitch)
        self.pitch_value_label = QLabel("1.0")
        pitch_layout.addWidget(pitch_label)
        pitch_layout.addWidget(self.pitch_slider)
        pitch_layout.addWidget(self.pitch_value_label)
        
        energy_layout = QHBoxLayout()
        energy_label = QLabel("√Çm l∆∞·ª£ng:")
        self.energy_slider = QSlider(Qt.Horizontal)
        self.energy_slider.setRange(50, 150)
        self.energy_slider.setValue(100)
        self.energy_slider.valueChanged.connect(self.update_energy)
        self.energy_value_label = QLabel("1.0")
        energy_layout.addWidget(energy_label)
        energy_layout.addWidget(self.energy_slider)
        energy_layout.addWidget(self.energy_value_label)
        
        duration_layout = QHBoxLayout()
        duration_label = QLabel("T·ªëc ƒë·ªô:")
        self.duration_slider = QSlider(Qt.Horizontal)
        self.duration_slider.setRange(50, 150)
        self.duration_slider.setValue(100)
        self.duration_slider.valueChanged.connect(self.update_duration)
        self.duration_value_label = QLabel("1.0")
        duration_layout.addWidget(duration_label)
        duration_layout.addWidget(self.duration_slider)
        duration_layout.addWidget(self.duration_value_label)
        
        control_layout.addLayout(pitch_layout)
        control_layout.addLayout(energy_layout)
        control_layout.addLayout(duration_layout)
        
        # Spectrogram display
        self.canvas = SpectrogramCanvas(self, width=8, height=3)
        
        # Status section
        self.status_label = QLabel("Tr·∫°ng th√°i: Vui l√≤ng t·∫£i models...")
        self.status_label.setStyleSheet("color: blue;")
        
        # Assemble the layout
        main_layout.addWidget(self.text_label)
        main_layout.addWidget(self.text_input)
        main_layout.addWidget(self.language_label)
        main_layout.addWidget(self.multi_language_checkbox)
        main_layout.addLayout(button_layout)
        main_layout.addLayout(control_layout)
        main_layout.addWidget(self.canvas)
        main_layout.addWidget(self.status_label)
        
        main_widget.setLayout(main_layout)
        self.setCentralWidget(main_widget)

    def toggle_multi_language_mode(self, checked):
        """Chuy·ªÉn ƒë·ªïi ch·∫ø ƒë·ªô ƒëa ng√¥n ng·ªØ"""
        self.multi_language_mode = checked
        if checked:
            self.status_label.setText("Tr·∫°ng th√°i: ƒê√£ b·∫≠t ch·∫ø ƒë·ªô ƒëa ng√¥n ng·ªØ ‚úÖ")
            self.status_label.setStyleSheet("color: green;")
        else:
            text = self.text_input.toPlainText().strip()
            if text:
                detected_lang = self.detect_language(text)
                self.current_language = detected_lang
                lang_name = "Ti·∫øng Vi·ªát üáªüá≥" if detected_lang == "vi" else "Ti·∫øng Anh üá¨üáß"
                self.language_label.setText(f"Ng√¥n ng·ªØ ph√°t hi·ªán: {lang_name}")
            self.status_label.setText("Tr·∫°ng th√°i: ƒê√£ t·∫Øt ch·∫ø ƒë·ªô ƒëa ng√¥n ng·ªØ")
            self.status_label.setStyleSheet("color: blue;")
        
    def on_text_changed(self):
        """X·ª≠ l√Ω khi vƒÉn b·∫£n thay ƒë·ªïi"""
        text = self.text_input.toPlainText().strip()
        if text:
            if self.multi_language_mode:
                segments = self.split_text_by_language(text)
                lang_info = []
                for segment, lang in segments:
                    lang_name = "Ti·∫øng Vi·ªát" if lang == "vi" else "Ti·∫øng Anh"
                    lang_info.append(f"{segment} ({lang_name})")
                
                if lang_info:
                    self.language_label.setText(f"Ph√¢n ƒëo·∫°n ng√¥n ng·ªØ: {len(segments)} ƒëo·∫°n vƒÉn b·∫£n")
                    self.status_label.setText(f"ƒê√£ ph√¢n t√≠ch th√†nh {len(segments)} ƒëo·∫°n vƒÉn b·∫£n kh√°c nhau")
                    self.status_label.setStyleSheet("color: green;")
                else:
                    self.language_label.setText("Ng√¥n ng·ªØ ph√°t hi·ªán: Ch∆∞a th·ªÉ ph√¢n ƒëo·∫°n")
                    self.language_label.setStyleSheet("color: orange;")
            else:
                detected_lang = self.detect_language(text)
                self.current_language = detected_lang
                lang_name = "Ti·∫øng Vi·ªát üáªüá≥" if detected_lang == "vi" else "Ti·∫øng Anh üá¨üáß"
                self.language_label.setText(f"Ng√¥n ng·ªØ ph√°t hi·ªán: {lang_name}")
                self.language_label.setStyleSheet("color: green;")
        else:
            self.language_label.setText("Ng√¥n ng·ªØ ph√°t hi·ªán: Ch∆∞a c√≥ vƒÉn b·∫£n")
            self.language_label.setStyleSheet("color: blue;")

    def generate_speech(self):
        try:
            text = self.text_input.toPlainText().strip()
            if not text:
                QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Vui l√≤ng nh·∫≠p vƒÉn b·∫£n!")
                return
            
            # Ki·ªÉm tra model ƒë√£ t·∫£i ch∆∞a
            if not self.vi_model and not self.en_model:
                QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Vui l√≤ng t·∫£i √≠t nh·∫•t m·ªôt model tr∆∞·ªõc!")
                return
            elif not self.vi_model and (self.current_language == "vi" or self.multi_language_mode):
                QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Vui l√≤ng t·∫£i model ti·∫øng Vi·ªát tr∆∞·ªõc!")
                return
            elif not self.en_model and (self.current_language == "en" or self.multi_language_mode):
                QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Vui l√≤ng t·∫£i model ti·∫øng Anh tr∆∞·ªõc!")
                return
            
            self.status_label.setText("Tr·∫°ng th√°i: ƒêang t·∫°o audio... üîÑ")
            self.status_label.setStyleSheet("color: blue;")
            QApplication.processEvents()
            
            if self.multi_language_mode:
                self.generate_multi_language_speech(text)
            else:
                self.generate_single_language_speech(text)
                
        except Exception as e:
            self.status_label.setText(f"Tr·∫°ng th√°i: L·ªói t·∫°o audio! ‚ùå")
            self.status_label.setStyleSheet("color: red;")
            QMessageBox.critical(self, "L·ªói ‚ùå", f"Kh√¥ng th·ªÉ t·∫°o audio: {str(e)}")
            print(f"Error generating speech: {e}")
    
    def generate_single_language_speech(self, text):
        """T·∫°o gi·ªçng n√≥i s·ª≠ d·ª•ng m·ªôt ng√¥n ng·ªØ"""
        # Ch·ªçn config v√† model theo ng√¥n ng·ªØ
        if self.current_language == "vi":
            model = self.vi_model
            vocoder = self.vi_vocoder
            preprocess_config = self.vi_preprocess_config
            model_config = self.vi_model_config
            train_config = self.vi_train_config
            stats = self.vi_stats
            text_sequence = preprocess_vietnamese(text, preprocess_config)
            output_dir = "output/result/temp_vi"
        else:  # English
            model = self.en_model
            vocoder = self.en_vocoder
            preprocess_config = self.en_preprocess_config
            model_config = self.en_model_config
            train_config = self.en_train_config
            stats = self.en_stats
            text_sequence = preprocess_english(text, preprocess_config)
            output_dir = "output/result/temp_en"
        
        # T·∫°o batch gi·ªëng nh∆∞ trong synthesize.py
        ids = raw_texts = [text[:100]]
        speakers = np.array([0])  # Speaker ID
        texts = np.array([text_sequence])
        text_lens = np.array([len(text_sequence)])
        batch = [(ids, raw_texts, speakers, texts, text_lens, max(text_lens))]
        
        # T·ªïng h·ª£p gi·ªçng n√≥i
        control_values = (self.pitch_control, self.energy_control, self.duration_control)
        
        with torch.no_grad():
            # Convert batch to device
            batch_device = to_device(batch[0], self.device)
            
            # Ch·∫°y model
            output = model(
                *(batch_device[2:]),
                p_control=control_values[0],
                e_control=control_values[1],
                d_control=control_values[2]
            )
            
            # Extract data t·ª´ output
            src_len = output[8][0].item()
            mel_len = output[9][0].item()
            mel_prediction = output[1][0, :mel_len].detach().transpose(0, 1)
            duration = output[5][0, :src_len].detach().cpu().numpy()
            
            # X·ª≠ l√Ω pitch
            if preprocess_config["preprocessing"]["pitch"]["feature"] == "phoneme_level":
                pitch = output[2][0, :src_len].detach().cpu().numpy()
                from utils.tools import expand
                pitch = expand(pitch, duration)
            else:
                pitch = output[2][0, :mel_len].detach().cpu().numpy()
            
            # X·ª≠ l√Ω energy
            if preprocess_config["preprocessing"]["energy"]["feature"] == "phoneme_level":
                energy = output[3][0, :src_len].detach().cpu().numpy()
                from utils.tools import expand
                energy = expand(energy, duration)
            else:
                energy = output[3][0, :mel_len].detach().cpu().numpy()
            
            # Hi·ªÉn th·ªã spectrogram
            self.canvas.plot_spectrogram(mel_prediction.cpu().numpy(), pitch, energy, stats)
            
            # T·∫°o file √¢m thanh
            from utils.model import vocoder_infer
            
            mel_predictions = output[1].transpose(1, 2)
            lengths = output[9] * preprocess_config["preprocessing"]["stft"]["hop_length"]
            wav_predictions = vocoder_infer(
                mel_predictions, vocoder, model_config, preprocess_config, lengths=lengths
            )
            
            # L∆∞u file t·∫°m ƒë·ªÉ ph√°t
            sampling_rate = preprocess_config["preprocessing"]["audio"]["sampling_rate"]
            import scipy.io.wavfile as wavfile
            
            # T·∫°o th∆∞ m·ª•c output n·∫øu ch∆∞a t·ªìn t·∫°i
            os.makedirs(output_dir, exist_ok=True)
            
            self.audio_path = f"{output_dir}/output.wav"
            wavfile.write(self.audio_path, sampling_rate, wav_predictions[0])
            
            self.status_label.setText(f"Tr·∫°ng th√°i: ƒê√£ t·∫°o audio {self.current_language.upper()} th√†nh c√¥ng! ‚úÖ")
            self.status_label.setStyleSheet("color: green;")
            QMessageBox.information(self, "Th√†nh c√¥ng ‚úÖ", f"ƒê√£ t·∫°o audio th√†nh c√¥ng ({self.current_language.upper()})!")
    
    def generate_multi_language_speech(self, text):
        """T·∫°o gi·ªçng n√≥i ƒëa ng√¥n ng·ªØ"""
        # Ph√¢n t√°ch vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n theo ng√¥n ng·ªØ
        segments = self.split_text_by_language(text)
        
        if not segments:
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Kh√¥ng th·ªÉ ph√¢n t√°ch vƒÉn b·∫£n th√†nh c√°c ƒëo·∫°n ng√¥n ng·ªØ!")
            return
            
        self.status_label.setText(f"Tr·∫°ng th√°i: ƒêang t·∫°o audio cho {len(segments)} ƒëo·∫°n vƒÉn b·∫£n... üîÑ")
        QApplication.processEvents()
        
        # T·∫°o th∆∞ m·ª•c t·∫°m n·∫øu ch∆∞a t·ªìn t·∫°i
        output_dir = "output/result/temp_multi"
        os.makedirs(output_dir, exist_ok=True)
        
        # T·∫°o danh s√°ch c√°c file √¢m thanh t·∫°m
        temp_audio_files = []
        
        # T·∫°o √¢m thanh cho t·ª´ng ƒëo·∫°n
        for i, (segment_text, lang) in enumerate(segments):
            try:
                # Ch·ªçn config v√† model theo ng√¥n ng·ªØ c·ªßa ƒëo·∫°n
                if lang == "vi":
                    if not self.vi_model:
                        continue  # B·ªè qua n·∫øu kh√¥ng c√≥ model ti·∫øng Vi·ªát
                        
                    model = self.vi_model
                    vocoder = self.vi_vocoder
                    preprocess_config = self.vi_preprocess_config
                    model_config = self.vi_model_config
                    train_config = self.vi_train_config
                    text_sequence = preprocess_vietnamese(segment_text, preprocess_config)
                else:  # English
                    if not self.en_model:
                        continue  # B·ªè qua n·∫øu kh√¥ng c√≥ model ti·∫øng Anh
                        
                    model = self.en_model
                    vocoder = self.en_vocoder
                    preprocess_config = self.en_preprocess_config
                    model_config = self.en_model_config
                    train_config = self.en_train_config
                    text_sequence = preprocess_english(segment_text, preprocess_config)
                
                # T·∫°o batch
                ids = raw_texts = [segment_text[:100]]
                speakers = np.array([0])  # Speaker ID
                texts = np.array([text_sequence])
                text_lens = np.array([len(text_sequence)])
                batch = [(ids, raw_texts, speakers, texts, text_lens, max(text_lens))]
                
                # T·ªïng h·ª£p gi·ªçng n√≥i
                control_values = (self.pitch_control, self.energy_control, self.duration_control)
                
                with torch.no_grad():
                    # Convert batch to device
                    batch_device = to_device(batch[0], self.device)
                    
                    # Ch·∫°y model
                    output = model(
                        *(batch_device[2:]),
                        p_control=control_values[0],
                        e_control=control_values[1],
                        d_control=control_values[2]
                    )
                    
                    # T·∫°o file √¢m thanh
                    from utils.model import vocoder_infer
                    
                    mel_predictions = output[1].transpose(1, 2)
                    lengths = output[9] * preprocess_config["preprocessing"]["stft"]["hop_length"]
                    wav_predictions = vocoder_infer(
                        mel_predictions, vocoder, model_config, preprocess_config, lengths=lengths
                    )
                    
                    # L∆∞u file t·∫°m
                    sampling_rate = preprocess_config["preprocessing"]["audio"]["sampling_rate"]
                    import scipy.io.wavfile as wavfile
                    
                    temp_file = f"{output_dir}/segment_{i}.wav"
                    wavfile.write(temp_file, sampling_rate, wav_predictions[0])
                    temp_audio_files.append((temp_file, sampling_rate))
                    
                    self.status_label.setText(f"Tr·∫°ng th√°i: ƒê√£ t·∫°o audio cho ƒëo·∫°n {i+1}/{len(segments)}... üîÑ")
                    QApplication.processEvents()
                    
            except Exception as e:
                print(f"L·ªói t·∫°o audio cho ƒëo·∫°n {i}: {e}")
                continue
        
        if not temp_audio_files:
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Kh√¥ng th·ªÉ t·∫°o audio cho b·∫•t k·ª≥ ƒëo·∫°n n√†o!")
            return
            
        # Gh√©p c√°c file √¢m thanh
        try:
            combined_audio = None
            
            for temp_file, _ in temp_audio_files:
                segment_audio = AudioSegment.from_wav(temp_file)
                
                if combined_audio is None:
                    combined_audio = segment_audio
                else:
                    combined_audio += segment_audio
            
            # L∆∞u file k·∫øt qu·∫£
            self.audio_path = f"{output_dir}/output_combined.wav"
            combined_audio.export(self.audio_path, format="wav")
            
            # Hi·ªÉn th·ªã th√¥ng b√°o th√†nh c√¥ng
            self.status_label.setText(f"Tr·∫°ng th√°i: ƒê√£ t·∫°o audio ƒëa ng√¥n ng·ªØ th√†nh c√¥ng! ‚úÖ")
            self.status_label.setStyleSheet("color: green;")
            QMessageBox.information(self, "Th√†nh c√¥ng ‚úÖ", f"ƒê√£ t·∫°o audio ƒëa ng√¥n ng·ªØ th√†nh c√¥ng!")
            
        except Exception as e:
            print(f"L·ªói gh√©p file √¢m thanh: {e}")
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", f"L·ªói khi gh√©p file √¢m thanh: {e}")
            
            # N·∫øu kh√¥ng gh√©p ƒë∆∞·ª£c, s·ª≠ d·ª•ng file cu·ªëi c√πng l√†m k·∫øt qu·∫£
            if temp_audio_files:
                self.audio_path = temp_audio_files[-1][0]
                self.status_label.setText(f"Tr·∫°ng th√°i: Kh√¥ng th·ªÉ gh√©p file √¢m thanh, hi·ªÉn th·ªã ƒëo·∫°n cu·ªëi c√πng! ‚ö†Ô∏è")
                self.status_label.setStyleSheet("color: orange;")

    def load_both_models(self):
        self.status_label.setText("Tr·∫°ng th√°i: ƒêang t·∫£i models... üîÑ")
        self.status_label.setStyleSheet("color: blue;")
        QApplication.processEvents()
        
        # T·∫£i model ti·∫øng Vi·ªát
        try:
            self.load_vietnamese_model()
            vi_loaded = True
        except Exception as e:
            vi_loaded = False
            print(f"Error loading Vietnamese model: {e}")
        
        # T·∫£i model ti·∫øng Anh
        try:
            self.load_english_model()
            en_loaded = True
        except Exception as e:
            en_loaded = False
            print(f"Error loading English model: {e}")
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        if vi_loaded and en_loaded:
            self.status_label.setText("Tr·∫°ng th√°i: ƒê√£ t·∫£i c·∫£ hai models th√†nh c√¥ng! ‚úÖ")
            self.status_label.setStyleSheet("color: green;")
            QMessageBox.information(self, "Th√†nh c√¥ng ‚úÖ", "ƒê√£ t·∫£i c·∫£ hai models th√†nh c√¥ng!")
        elif vi_loaded:
            self.status_label.setText("Tr·∫°ng th√°i: ƒê√£ t·∫£i model ti·∫øng Vi·ªát, model ti·∫øng Anh th·∫•t b·∫°i! ‚ö†Ô∏è")
            self.status_label.setStyleSheet("color: orange;")
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Ch·ªâ t·∫£i ƒë∆∞·ª£c model ti·∫øng Vi·ªát, model ti·∫øng Anh th·∫•t b·∫°i!")
        elif en_loaded:
            self.status_label.setText("Tr·∫°ng th√°i: ƒê√£ t·∫£i model ti·∫øng Anh, model ti·∫øng Vi·ªát th·∫•t b·∫°i! ‚ö†Ô∏è")
            self.status_label.setStyleSheet("color: orange;")
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Ch·ªâ t·∫£i ƒë∆∞·ª£c model ti·∫øng Anh, model ti·∫øng Vi·ªát th·∫•t b·∫°i!")
        else:
            self.status_label.setText("Tr·∫°ng th√°i: Kh√¥ng th·ªÉ t·∫£i c·∫£ hai models! ‚ùå")
            self.status_label.setStyleSheet("color: red;")
            QMessageBox.critical(self, "L·ªói ‚ùå", "Kh√¥ng th·ªÉ t·∫£i c·∫£ hai models!")
        
    def load_vietnamese_model(self):
        # ƒê·ªçc config
        self.vi_preprocess_config = yaml.load(
            open(self.vi_preprocess_config_path, "r"), Loader=yaml.FullLoader
        )
        self.vi_model_config = yaml.load(
            open(self.vi_model_config_path, "r"), Loader=yaml.FullLoader
        )
        self.vi_train_config = yaml.load(
            open(self.vi_train_config_path, "r"), Loader=yaml.FullLoader
        )
        
        # T·∫°o pseudo args ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi h√†m get_model
        class Args:
            def __init__(self, restore_step):
                self.restore_step = restore_step
        
        args = Args(self.vi_restore_step)
        
        # T·∫£i model
        self.vi_model = get_model(
            args,
            (self.vi_preprocess_config, self.vi_model_config, self.vi_train_config),
            self.device,
            train=False
        )
        
        # T·∫£i vocoder
        self.vi_vocoder = get_vocoder(self.vi_model_config, self.device)
        
        # ƒê·ªçc stats cho vi·ªác hi·ªÉn th·ªã spectrogram
        with open(
            os.path.join(self.vi_preprocess_config["path"]["preprocessed_path"], "stats.json")
        ) as f:
            import json
            stats = json.load(f)
            self.vi_stats = stats["pitch"] + stats["energy"][:2]
    
    def load_english_model(self):
        # ƒê·ªçc config
        self.en_preprocess_config = yaml.load(
            open(self.en_preprocess_config_path, "r"), Loader=yaml.FullLoader
        )
        self.en_model_config = yaml.load(
            open(self.en_model_config_path, "r"), Loader=yaml.FullLoader
        )
        self.en_train_config = yaml.load(
            open(self.en_train_config_path, "r"), Loader=yaml.FullLoader
        )
        
        # T·∫°o pseudo args ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi h√†m get_model
        class Args:
            def __init__(self, restore_step):
                self.restore_step = restore_step
        
        args = Args(self.en_restore_step)
        
        # T·∫£i model
        self.en_model = get_model(
            args,
            (self.en_preprocess_config, self.en_model_config, self.en_train_config),
            self.device,
            train=False
        )
        
        # T·∫£i vocoder
        self.en_vocoder = get_vocoder(self.en_model_config, self.device)
        
        # ƒê·ªçc stats cho vi·ªác hi·ªÉn th·ªã spectrogram
        with open(
            os.path.join(self.en_preprocess_config["path"]["preprocessed_path"], "stats.json")
        ) as f:
            import json
            stats = json.load(f)
            self.en_stats = stats["pitch"] + stats["energy"][:2]
    
    def update_pitch(self):
        self.pitch_control = self.pitch_slider.value() / 100
        self.pitch_value_label.setText(f"{self.pitch_control:.1f}")
        
    def update_energy(self):
        self.energy_control = self.energy_slider.value() / 100
        self.energy_value_label.setText(f"{self.energy_control:.1f}")
        
    def update_duration(self):
        self.duration_control = self.duration_slider.value() / 100
        self.duration_value_label.setText(f"{self.duration_control:.1f}")
    
    def play_audio(self):
        if not self.audio_path or not os.path.exists(self.audio_path):
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Ch∆∞a c√≥ file audio n√†o ƒë∆∞·ª£c t·∫°o!")
            return
            
        try:
            self.status_label.setText("Tr·∫°ng th√°i: ƒêang ph√°t audio... üîä")
            self.status_label.setStyleSheet("color: blue;")
            
            # Ph√°t file √¢m thanh
            url = QUrl.fromLocalFile(os.path.abspath(self.audio_path))
            content = QMediaContent(url)
            self.player.setMedia(content)
            self.player.play()
            
            # K·∫øt n·ªëi s·ª± ki·ªán k·∫øt th√∫c ph√°t
            self.player.stateChanged.connect(self.on_player_state_changed)
            
        except Exception as e:
            self.status_label.setText(f"Tr·∫°ng th√°i: L·ªói ph√°t audio! ‚ùå")
            self.status_label.setStyleSheet("color: red;")
            QMessageBox.critical(self, "L·ªói ‚ùå", f"Kh√¥ng th·ªÉ ph√°t audio: {str(e)}")
    
    def on_player_state_changed(self, state):
        if state == QMediaPlayer.StoppedState:
            self.status_label.setText("Tr·∫°ng th√°i: S·∫µn s√†ng ‚úÖ")
            self.status_label.setStyleSheet("color: green;")
    
    def save_audio(self):
        if not self.audio_path or not os.path.exists(self.audio_path):
            QMessageBox.warning(self, "C·∫£nh b√°o ‚ö†Ô∏è", "Ch∆∞a c√≥ file audio n√†o ƒë∆∞·ª£c t·∫°o!")
            return
            
        try:
            # M·ªü h·ªôp tho·∫°i l∆∞u file
            file_path, _ = QFileDialog.getSaveFileName(
                self, "L∆∞u File Audio", "", "WAV Files (*.wav);;All Files (*)"
            )
            
            if file_path:
                # Sao ch√©p file
                import shutil
                shutil.copy2(self.audio_path, file_path)
                self.status_label.setText(f"Tr·∫°ng th√°i: ƒê√£ l∆∞u file audio th√†nh c√¥ng! ‚úÖ")
                self.status_label.setStyleSheet("color: green;")
                QMessageBox.information(self, "Th√†nh c√¥ng ‚úÖ", f"ƒê√£ l∆∞u file audio t·∫°i: {file_path}")
        except Exception as e:
            self.status_label.setText(f"Tr·∫°ng th√°i: L·ªói l∆∞u audio! ‚ùå")
            self.status_label.setStyleSheet("color: red;")
            QMessageBox.critical(self, "L·ªói ‚ùå", f"Kh√¥ng th·ªÉ l∆∞u audio: {str(e)}")

if __name__ == "__main__":
    app = QApplication(sys.argv)
    window = DualModeTTSGUI()
    window.show()
    sys.exit(app.exec_()) 